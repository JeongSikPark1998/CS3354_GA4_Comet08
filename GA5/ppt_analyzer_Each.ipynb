{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install"
      ],
      "metadata": {
        "id": "QTBBMmkWP_Iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3OPWSpdP8z6"
      },
      "outputs": [],
      "source": [
        "!pip install python-pptx\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pptx\n",
        "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
        "\n",
        "!pip install openai\n",
        "import openai\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#your API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = '[YOUR_API_KEY]'\n",
        "\n",
        "#load ppt from the google drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(\"/content/gdrive/My Drive/analyzer/input_ppt\")"
      ],
      "metadata": {
        "id": "FuVhfPS8QA4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions"
      ],
      "metadata": {
        "id": "NM22fWXIQE6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatApp: #no demo, only template\n",
        "    def __init__(self, input):\n",
        "        # Setting the API key to use the OpenAI API\n",
        "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        self.messages = input\n",
        "\n",
        "    def chat(self, message):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=self.messages,\n",
        "            temperature=0.7,\n",
        "            top_p = 1,\n",
        "        )\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": response[\"choices\"][0][\"message\"].content})\n",
        "\n",
        "        for i in range(2):\n",
        "          self.messages.pop()\n",
        "\n",
        "        return response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "UwK2q_-WQA6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt_format(system, user, assistant): #prompt demonstration\n",
        "  #system\n",
        "  input = [{\"role\": \"system\", \"content\": system}]\n",
        "  if user != \"\":\n",
        "    #user\n",
        "    demo_user = []\n",
        "    demo_user.append(user)\n",
        "    #assistant\n",
        "    demo_assistant = []\n",
        "    demo_assistant.append(assistant)\n",
        "\n",
        "    #make format for API\n",
        "    demo = pd.DataFrame({'user': demo_user, 'assistant': demo_assistant})\n",
        "    for prompt, completion in zip(demo['user'], demo['assistant']):\n",
        "      message_dict = {\"role\": \"user\", \"content\": prompt}\n",
        "      input.append(message_dict)\n",
        "      message_dict = {\"role\": \"assistant\", \"content\": completion}\n",
        "      input.append(message_dict)\n",
        "    \n",
        "  return input"
      ],
      "metadata": {
        "id": "R3aluEXvQBSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "dcDfdsj9QHSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data"
      ],
      "metadata": {
        "id": "J9MCkLCuQJG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load ppt file\n",
        "ppt = pptx.Presentation('Architecture_Design.pptx')\n",
        "\n",
        "#for full slide\n",
        "full_slide = []\n",
        "content_full = \"Entire contents: \"\n",
        "for i, slide in enumerate(ppt.slides):\n",
        "  content_full = content_full + f\"  *slide {i}: \"\n",
        "  for shape in slide.shapes:\n",
        "    if hasattr(shape, \"text\"):\n",
        "      content_full = content_full + shape.text\n",
        "full_slide = content_full\n",
        "\n",
        "# print(\"*\"*10)\n",
        "# print(full_slide)\n",
        "\n",
        "#for each slide, keywords\n",
        "each_slide = {} #dictionary form\n",
        "for i, slide in enumerate(ppt.slides):\n",
        "  content_each = \"\"\n",
        "  for shape in slide.shapes:\n",
        "    if hasattr(shape, \"text\"):\n",
        "      content_each = content_each + shape.text\n",
        "  each_slide[f'{i}'] = content_each \n",
        "\n",
        "# print(\"*\"*10)\n",
        "# print(each_slide)"
      ],
      "metadata": {
        "id": "dKUcp-SdQIMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Each Slide"
      ],
      "metadata": {
        "id": "K9bW5MVQQMy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize each Powerpoint file."
      ],
      "metadata": {
        "id": "aQ_yeWZqQdnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt demonstration\n",
        "each_system = \"I want you to summarize the given content. I will provide you with the contents of a PowerPoint presentation, and you will provide me with a summary of the slide.\"\n",
        "each_user = \"Design flaws – a few examples What if the system does not handle multiple customers purchasing items simultaneously ?\\n\\t\\uf0e0the shopping cart becomes common for both customers! \\uf04c\\n\\nWhat if web server does too much processing for each transaction? \\n\\t\\uf0e0capacity of the web server comes down drastically & the web server crashes when too many requests come within a small-time window!\\n\\nWhat if the security requirements are ignored ? \\n\\t\\uf0e0hacker can manipulate the prices of items in the shopping cart \\n\\nWhat if the team misses to identify several generic components for which COTS are available ?\\n\\t\\uf0e0the team develops everything in-house…\\n\\n\\n\"\n",
        "each_assistant = \"The PowerPoint presentation highlights several design flaws such as the shopping cart becoming common for multiple customers, the web server crashing due to excessive processing, hackers manipulating prices due to ignored security requirements, and developing everything in-house due to missed identification of available COTS components.\"\n",
        "prompt_each = make_prompt_format(each_system, each_user, each_assistant)\n",
        "\n",
        "#summarize each slide\n",
        "result_each = {}\n",
        "app_each = ChatApp(prompt_each)\n",
        "for i in range(len(each_slide)):\n",
        "  message = each_slide[f'{i}']\n",
        "  res = app_each.chat(message)\n",
        "  time.sleep(3) #API call restriction, 20 calls per a minute\n",
        "  result_each[f'{i}'] = res\n",
        "\n",
        "#print result\n",
        "result_each"
      ],
      "metadata": {
        "id": "KG8bpQG1QBT_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}